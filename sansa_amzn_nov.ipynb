{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.sansa import SANSA\n",
    "\n",
    "sansa_config = {\n",
    "       \"l2\": 20.0,\n",
    "        \"target_density\": 5e-5,\n",
    "        \"ainv_params\": {\n",
    "            \"umr_scans\": 3,\n",
    "            \"umr_finetune_steps\": 10,\n",
    "            \"umr_loss_threshold\": 1e-4,\n",
    "        },\n",
    "        \"ldlt_method\": \"icf\"\n",
    "}\n",
    "     \n",
    "sansa = SANSA.from_config(sansa_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 14:08:22,913 : [1/3] DATASET : Loading processed dataset datasets/data/amazonbook/dataset.parquet.\n"
     ]
    }
   ],
   "source": [
    "# Load amazon books data\n",
    "\n",
    "from datasets.amazonbook import Amazonbook\n",
    "\n",
    "amazonbooks_data_config = {\n",
    "    \"name\": \"amazonbook\",\n",
    "    \"rewrite\": False,\n",
    "}\n",
    "\n",
    "amazonbooks_data = Amazonbook.from_config(amazonbooks_data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 14:09:15,848 : [1/3] DATASET : Dataframe lengths | train_df: 2380730, val_df: 2380730, test_df: 2984108\n",
      "2024-04-29 14:10:02,009 : [1/3] DATASET : Removing users [50736, 52234, 41589, 13647] from test inputs.\n",
      "2024-04-29 14:10:02,639 : [1/3] DATASET : Splits information:\n",
      "2024-04-29 14:10:02,640 : [1/3] DATASET : Train split info | n_users = 52643, n_items = 91599, n_ratings = 2380730, sparsity = 99.95%\n",
      "2024-04-29 14:10:02,641 : [1/3] DATASET : Validation split info | n_users = 52643, n_items = 91599, n_ratings = 2380730, sparsity = 99.95%\n",
      "2024-04-29 14:10:02,642 : [1/3] DATASET : Test split info | n_users = 52639, n_items = 91599, n_ratings = 2380661, sparsity = 99.95%\n",
      "2024-04-29 14:10:02,644 : [1/3] DATASET : Execution of create_splits took at 97.698 seconds.\n"
     ]
    }
   ],
   "source": [
    "amazon_split_config = {\n",
    "    \"seed\": 42,\n",
    "    \"val_target_proportion\": 0.0,\n",
    "}\n",
    "\n",
    "(amazon_train, amazon_val, amazon_test), amazon_split_time = amazonbooks_data.create_splits(amazon_split_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 14:10:30,034 : [2/3] TRAINING : Train user-item matrix info | n_users = 52643, n_items = 91599, n_ratings = 2380730, sparsity = 99.95%\n",
      "2024-04-29 14:10:30,037 : [2/3] TRAINING : Item-item matrix info | shape = (91599,91599)\n",
      "2024-04-29 14:10:30,038 : [2/3] TRAINING : Training SANSA with L2=20.0, target density=0.005000%, LDL^T method=icf, approx. inverse method=umr...\n",
      "2024-04-29 14:10:30,039 : [2/3] TRAINING : Loading item-user matrix...\n",
      "2024-04-29 14:10:30,179 : [2/3] TRAINING : Constructing weights:\n",
      "2024-04-29 14:10:39,884 : [2/3] TRAINING : Constructing A...\n",
      "2024-04-29 14:10:42,083 : [2/3] TRAINING : A info | nnz: 330335853, size: 3964.4 MB\n",
      "2024-04-29 14:10:56,577 : [2/3] TRAINING : Computing incomplete LL^T decomposition...\n",
      "2024-04-29 14:11:27,482 : [2/3] TRAINING : L info | nnz: 419506, size: 5.400 MB, density: 0.005000%\n",
      "2024-04-29 14:11:27,484 : [2/3] TRAINING : Scaling columns and creating D (LL^T -> L'DL'^T)\n",
      "2024-04-29 14:11:27,498 : [2/3] TRAINING : Execution of ldlt took at 57.318 seconds.\n",
      "2024-04-29 14:11:27,499 : [2/3] TRAINING : nnz of L: 419506, size: 5.400 MB\n",
      "2024-04-29 14:11:27,500 : [2/3] TRAINING : Computing approximate inverse of L:\n",
      "2024-04-29 14:11:27,501 : [2/3] TRAINING : Calculating initial guess using 1 step of Schultz method...\n",
      "2024-04-29 14:11:27,509 : [2/3] TRAINING : Calculating approximate inverse using Uniform Minimal Residual algorithm...\n",
      "2024-04-29 14:11:27,534 : [2/3] TRAINING : Current maximum residual: 0.00130818, relative Frobenius norm squared: 0.00000001\n",
      "2024-04-29 14:11:27,535 : [2/3] TRAINING : Reached stopping criterion.\n",
      "2024-04-29 14:11:27,558 : [2/3] TRAINING : Current maximum residual: 0.00130818, relative Frobenius norm squared: 0.00000001\n",
      "2024-04-29 14:11:27,565 : [2/3] TRAINING : Execution of ainv_L took at 0.064 seconds.\n",
      "2024-04-29 14:11:27,566 : [2/3] TRAINING : nnz of L_inv: 419506, size: 5.400 MB\n",
      "2024-04-29 14:11:27,566 : [2/3] TRAINING : Constructing W = L_inv @ P...\n",
      "2024-04-29 14:11:27,590 : [2/3] TRAINING : Extracting diagonal of W.T @ D_inv @ W...\n",
      "2024-04-29 14:11:27,597 : [2/3] TRAINING : Dividing columns of W by diagonal entries...\n",
      "2024-04-29 14:11:27,708 : [2/3] TRAINING : Execution of _construct_weights took at 57.528 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Train Sansa\n",
    "sansa.train(amazon_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-27 17:36:45,462 : [3/3] EVALUATION : Execution of _matmat took at 0.076 seconds.\n",
      "2024-04-27 17:36:45,804 : [3/3] EVALUATION : Execution of _matmat took at 0.340 seconds.\n",
      "2024-04-27 17:36:48,201 : [3/3] EVALUATION : Execution of _predict took at 2.814 seconds.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Evaluate on novelty\n",
    "# Get all users\n",
    "users = list(amazon_test.user_encoder.classes_)\n",
    "# Get rated items of users\n",
    "users_rated = amazon_test.get_rated_items(users)\n",
    "targets = amazon_test.get_target_items(users)\n",
    "target_ids_dict = (\n",
    "    targets.groupby(\"user_id\", group_keys=True)[\"item_id\"]\n",
    "    .apply(list)\n",
    "    .to_dict()\n",
    ")\n",
    "keys = list(target_ids_dict.keys())\n",
    "users_to_arange = {user: i for i, user in enumerate(keys)}\n",
    "pd.options.mode.chained_assignment = None  # suppress irrelevant warning\n",
    "users_rated[\"user_id\"] = users_rated[\"user_id\"].map(users_to_arange)\n",
    "pd.options.mode.chained_assignment = \"warn\"\n",
    "top_maxk_ids, top_maxk_scores = sansa.recommend(users_rated, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of item occurences for novelty metric\n",
    "training_csr_matrix = amazon_train.get_csr_matrix()\n",
    "item_occurrences = training_csr_matrix.sum(axis=0)\n",
    "item_ids = item_occurrences.nonzero()[1]\n",
    "# Get the occurrences as a numpy array\n",
    "item_occurrences = item_occurrences.A1\n",
    "    \n",
    "# Create a dictionary of item IDs and their occurrences\n",
    "item_occurrences_dict = dict(zip(item_ids, item_occurrences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import recmetrics\n",
    "\n",
    "amazon_book_novelty, amazon_book_novelty_topn = recmetrics.novelty(top_maxk_ids, item_occurrences_dict, len(users), 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.840958832420865"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_book_novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sansa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
