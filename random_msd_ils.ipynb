{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 13:10:17,635 : [1/3] DATASET : Creating new dataset msd:\n",
      "2024-04-29 13:10:17,636 : [1/3] DATASET : Loading raw dataset files from datasets/data/msd/ ...\n",
      "2024-04-29 13:14:19,877 : [1/3] DATASET : Unifying dataset format...\n",
      "2024-04-29 13:14:35,285 : [1/3] DATASET : Preprocessing dataset...\n",
      "2024-04-29 13:16:14,031 : [1/3] DATASET : Saving processed dataset datasets/data/msd/dataset.parquet...\n"
     ]
    }
   ],
   "source": [
    "# Load msd data. If there is a parquet file, it will not call read_raw_data\n",
    "\n",
    "from datasets.msd import MSD\n",
    "\n",
    "msd_data_config = {\n",
    "    \"name\": \"msd\",\n",
    "    \"rewrite\": False,\n",
    "}\n",
    "\n",
    "msd_dataset = MSD.from_config(msd_data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 13:28:35,456 : [1/3] DATASET : Dataframe lengths | train_df: 28917900, val_df: 2352979, test_df: 2362570\n",
      "2024-04-29 13:29:54,524 : [1/3] DATASET : Splits information:\n",
      "2024-04-29 13:29:54,529 : [1/3] DATASET : Train split info | n_users = 491355, n_items = 41140, n_ratings = 28917900, sparsity = 99.86%\n",
      "2024-04-29 13:29:54,530 : [1/3] DATASET : Validation split info | n_users = 40000, n_items = 41140, n_ratings = 1897726, sparsity = 99.88%\n",
      "2024-04-29 13:29:54,531 : [1/3] DATASET : Test split info | n_users = 40000, n_items = 41140, n_ratings = 1905499, sparsity = 99.88%\n",
      "2024-04-29 13:29:54,532 : [1/3] DATASET : Execution of create_splits took at 98.026 seconds.\n"
     ]
    }
   ],
   "source": [
    "msd_split_config = {\n",
    "    \"n_val_users\": 40000,\n",
    "    \"n_test_users\": 40000,\n",
    "    \"seed\": 42,\n",
    "    \"target_proportion\": 0.2,\n",
    "    \"targets_newest\": False,\n",
    "}\n",
    "\n",
    "\n",
    "(msd_train, msd_val, msd_test), msd_split_time = msd_dataset.create_splits(msd_split_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you run into AttributeError: 'NoneType' object has no attribute 'inverse_transform' delete the parquet file \n",
    "# under datasets/data/msd/\n",
    "\n",
    "# Train and test use the same songs, so we don't have to get ALL song data\n",
    "# Get unencoded item ids\n",
    "item_ids = msd_dataset.item_decoder.inverse_transform(msd_train.item_encoder.classes_)\n",
    "\n",
    "# maps song id to item id\n",
    "mapping_dict = {}\n",
    "for item_id, encoded_id in zip(item_ids, msd_train.item_encoder.classes_):\n",
    "    mapping_dict[item_id] = encoded_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of songs that could be mapped to a track: 386213\n",
      "Num of songs that could not be mapped to a track: 2380\n",
      "Num of songs that have genres: 280831\n",
      "Num of songs that do not have genres: 0\n"
     ]
    }
   ],
   "source": [
    "# Get song to track mappings\n",
    "raw_item_ids_mappings = \"datasets/metadata/msd/taste_profile_song_to_tracks.txt\"\n",
    "\n",
    "# maps song id to track id\n",
    "song_to_track = {}\n",
    "no_mapping_cnt = 0\n",
    "with open(raw_item_ids_mappings) as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        line = line.split()\n",
    "\n",
    "        song_id = line[0]\n",
    "        # songs can map to multiple tracks\n",
    "        track_ids = line[1:]\n",
    "\n",
    "        if len(track_ids) > 0:\n",
    "            song_to_track[song_id] = track_ids[0]\n",
    "        else:\n",
    "            song_to_track[song_id] = 'DNE'\n",
    "            no_mapping_cnt += 1\n",
    "\n",
    "print(\"Num of songs that could be mapped to a track: \" + str(len(song_to_track)))\n",
    "print(\"Num of songs that could not be mapped to a track: \" + str(no_mapping_cnt))\n",
    "\n",
    "\n",
    "# Get genres of all songs\n",
    "raw_genre_data = \"datasets/metadata/msd/msd_tagtraum_cd2.txt\"\n",
    "\n",
    "track_id_genre = {}\n",
    "no_mapping_cnt = 0\n",
    "with open(raw_genre_data) as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        line = line.split()\n",
    "\n",
    "        track_id = line[0]\n",
    "        # tracks can have multiple genres\n",
    "        track_genres = line[1:]\n",
    "\n",
    "        if len(track_ids) > 0:\n",
    "            track_id_genre[track_id] = track_genres[0]\n",
    "        else:\n",
    "            track_id_genre[track_id] = 'No genre'\n",
    "            no_mapping_cnt += 1\n",
    "\n",
    "print(\"Num of songs that have genres: \" + str(len(track_id_genre)))\n",
    "print(\"Num of songs that do not have genres: \" + str(no_mapping_cnt))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_item_ids_to_track_ids = {}\n",
    "\n",
    "for item_id in item_ids:\n",
    "    if item_id in song_to_track:\n",
    "        if song_to_track[item_id] in track_id_genre:\n",
    "            train_item_ids_to_track_ids[mapping_dict[item_id]] = track_id_genre[song_to_track[item_id]]\n",
    "        else:\n",
    "            train_item_ids_to_track_ids[mapping_dict[item_id]] = \"none\"\n",
    "    else:\n",
    "        train_item_ids_to_track_ids[mapping_dict[item_id]] = \"none\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  genre\n",
       "0   Pop\n",
       "1  none\n",
       "2  none\n",
       "3  none\n",
       "4  Rock"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "item_genres_df = pd.DataFrame.from_dict(train_item_ids_to_track_ids, orient='index', columns=['genre'])\n",
    "item_genres_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       blues  country  electronic  folk  jazz  latin  metal  new  none  pop  \\\n",
      "0        0.0      0.0         0.0   0.0   0.0    0.0    0.0  0.0   0.0  1.0   \n",
      "1        0.0      0.0         0.0   0.0   0.0    0.0    0.0  0.0   1.0  0.0   \n",
      "2        0.0      0.0         0.0   0.0   0.0    0.0    0.0  0.0   1.0  0.0   \n",
      "3        0.0      0.0         0.0   0.0   0.0    0.0    0.0  0.0   1.0  0.0   \n",
      "4        0.0      0.0         0.0   0.0   0.0    0.0    0.0  0.0   0.0  0.0   \n",
      "...      ...      ...         ...   ...   ...    ...    ...  ...   ...  ...   \n",
      "41135    0.0      0.0         0.0   0.0   0.0    0.0    0.0  1.0   0.0  0.0   \n",
      "41136    0.0      0.0         0.0   0.0   0.0    0.0    1.0  0.0   0.0  0.0   \n",
      "41137    0.0      0.0         1.0   0.0   0.0    0.0    0.0  0.0   0.0  0.0   \n",
      "41138    0.0      0.0         0.0   0.0   0.0    0.0    1.0  0.0   0.0  0.0   \n",
      "41139    0.0      0.0         0.0   0.0   0.0    0.0    0.0  0.0   0.0  0.0   \n",
      "\n",
      "       punk  rap  reggae  rnb  rock  world  \n",
      "0       0.0  0.0     0.0  0.0   0.0    0.0  \n",
      "1       0.0  0.0     0.0  0.0   0.0    0.0  \n",
      "2       0.0  0.0     0.0  0.0   0.0    0.0  \n",
      "3       0.0  0.0     0.0  0.0   0.0    0.0  \n",
      "4       0.0  0.0     0.0  0.0   1.0    0.0  \n",
      "...     ...  ...     ...  ...   ...    ...  \n",
      "41135   0.0  0.0     0.0  0.0   0.0    0.0  \n",
      "41136   0.0  0.0     0.0  0.0   0.0    0.0  \n",
      "41137   0.0  0.0     0.0  0.0   0.0    0.0  \n",
      "41138   0.0  0.0     0.0  0.0   0.0    0.0  \n",
      "41139   0.0  0.0     0.0  0.0   1.0    0.0  \n",
      "\n",
      "[41140 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(strip_accents='ascii')  # Initialize a TF-IDF vectorizer\n",
    "tfidf_matrix = vectorizer.fit_transform(item_genres_df['genre'])\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()  # Get the vocabulary \n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), \n",
    "                        columns=feature_names, \n",
    "                        index=item_genres_df.index)\n",
    "\n",
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.randomrec import RANDOM_REC\n",
    "\n",
    "# No need to train, just predict\n",
    "ran_pred = RANDOM_REC(msd_test.data, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3563305263157895\n"
     ]
    }
   ],
   "source": [
    "import recmetrics\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "ran_pred_np = np.array(ran_pred)\n",
    "ran_pred_np = ran_pred_np.tolist()\n",
    "\n",
    "msd_ils = recmetrics.intra_list_similarity(ran_pred_np, tfidf_df)\n",
    "\n",
    "print(msd_ils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sansa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
