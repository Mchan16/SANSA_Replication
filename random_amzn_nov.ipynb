{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 10:45:34,792 : [1/3] DATASET : Loading processed dataset datasets/data/amazonbook/dataset.parquet.\n"
     ]
    }
   ],
   "source": [
    "# Load amazon books data\n",
    "\n",
    "from datasets.amazonbook import Amazonbook\n",
    "\n",
    "amazonbooks_data_config = {\n",
    "    \"name\": \"amazonbook\",\n",
    "    \"rewrite\": False,\n",
    "}\n",
    "\n",
    "amazonbooks_data = Amazonbook.from_config(amazonbooks_data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 10:46:25,468 : [1/3] DATASET : Dataframe lengths | train_df: 2380730, val_df: 2380730, test_df: 2984108\n",
      "2024-04-29 10:47:11,637 : [1/3] DATASET : Removing users [50736, 52234, 41589, 13647] from test inputs.\n",
      "2024-04-29 10:47:12,271 : [1/3] DATASET : Splits information:\n",
      "2024-04-29 10:47:12,272 : [1/3] DATASET : Train split info | n_users = 52643, n_items = 91599, n_ratings = 2380730, sparsity = 99.95%\n",
      "2024-04-29 10:47:12,273 : [1/3] DATASET : Validation split info | n_users = 52643, n_items = 91599, n_ratings = 2380730, sparsity = 99.95%\n",
      "2024-04-29 10:47:12,274 : [1/3] DATASET : Test split info | n_users = 52639, n_items = 91599, n_ratings = 2380661, sparsity = 99.95%\n",
      "2024-04-29 10:47:12,276 : [1/3] DATASET : Execution of create_splits took at 97.194 seconds.\n"
     ]
    }
   ],
   "source": [
    "amazon_split_config = {\n",
    "    \"seed\": 42,\n",
    "    \"val_target_proportion\": 0.0,\n",
    "}\n",
    "\n",
    "(amazon_train, amazon_val, amazon_test), amazon_split_time = amazonbooks_data.create_splits(amazon_split_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of item occurences for novelty metric\n",
    "training_csr_matrix = amazon_train.get_csr_matrix()\n",
    "item_occurrences = training_csr_matrix.sum(axis=0)\n",
    "item_ids = item_occurrences.nonzero()[1]\n",
    "# Get the occurrences as a numpy array\n",
    "item_occurrences = item_occurrences.A1\n",
    "    \n",
    "# Create a dictionary of item IDs and their occurrences\n",
    "item_occurrences_dict = dict(zip(item_ids, item_occurrences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.randomrec import RANDOM_REC\n",
    "\n",
    "# No need to train, just predict\n",
    "ran_pred = RANDOM_REC(amazon_test.data, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.579565591315276"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import recmetrics\n",
    "\n",
    "amazon_book_novelty, amazon_book_novelty_topn = recmetrics.novelty(ran_pred, item_occurrences_dict, len(amazon_test.data['user_id'].unique().tolist()), 20)\n",
    "\n",
    "amazon_book_novelty"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sansa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
